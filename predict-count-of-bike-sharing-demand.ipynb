{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"Bike sharing systems are a means of renting bicycles where the process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout a city. Using these systems, people can rent a bike from one location and return it to a different place on an as-needed basis. \n\nThis dataset contains valuable information about bike rentals, including various features such as datetime, weather conditions, and holidays. The dataset provided hourly rental data spanning two years. For this competition, the training set is comprised of the first 19 days of each month, while the test set is from the 20th to the end of the month.\n\nBy harnessing the power of regression algorithms, this project aims to predict the total count of bikes rented during each hour covered by the test set, based on only information available before the rental period. By evaluating the performance of different regression models using the Root Mean Squared Logarithmic Error (RMSLE), we will select the most accurate model that best captures the underlying relationships within the data.\n\nUltimately, the goal of this project is to not only develop a reliable prediction model but also through a comprehensive analysis of the dataset, this project seeks to unearth meaningful insights about the factors influencing bike rentals. These insights could potentially aid stakeholders in making informed decisions to optimize bike availability, marketing strategies, and resource allocation.","metadata":{}},{"cell_type":"markdown","source":"### Understanding the Variables","metadata":{}},{"cell_type":"markdown","source":"1. datetime: hourly date + timestamp  \nClear, Few clouds, Partly cloudy, Partly cloudy\n\n2. season:    \n           1 = spring   \n           2 = summer\n           3 = fall\n           4 = winter\n           \n           \n3. holiday: whether the day is considered a holiday, \n             1 = holiday \n             0 = not holiday\n            \n\n4. workingday: whether the day is neither a weekend nor holiday\n                1 = working day \n                0 = not working day\n               \n\n5. weather: \n            1 = Clear, Few clouds, Partly cloudy, Partly cloudy\n            2 = Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n            3 = Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n            4 = Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n            \n            \n6. temp: temperature in Celsius\n\n7. atemp: \"feels like\" temperature in Celsius\n\n8. humidity: relative humidity\n\n9. windspeed: wind speed\n\n10. casual: number of non-registered user rentals initiated\n\n11. registered: number of registered user rentals initiated\n\n12. count: number of total rentals","metadata":{}},{"cell_type":"code","source":"# Import libraries. begin, let's import the necessary libraries that we'll be using throughout this notebook:\n\n# Data Manipulation Libraries\nimport numpy as np \nimport pandas as pd \n\n# Data Visualization Libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Machine Learning Libraries\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import mean_squared_log_error, make_scorer\n\n# Machine Learning Models\nfrom sklearn.linear_model import LinearRegression  \nfrom sklearn.tree import DecisionTreeRegressor  \nfrom sklearn.ensemble import RandomForestRegressor","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-14T05:06:17.117010Z","iopub.execute_input":"2023-08-14T05:06:17.119072Z","iopub.status.idle":"2023-08-14T05:06:17.125577Z","shell.execute_reply.started":"2023-08-14T05:06:17.119033Z","shell.execute_reply":"2023-08-14T05:06:17.124696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# knowing the name of the dataset.\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.142457Z","iopub.execute_input":"2023-08-14T05:06:17.143071Z","iopub.status.idle":"2023-08-14T05:06:17.151505Z","shell.execute_reply.started":"2023-08-14T05:06:17.143034Z","shell.execute_reply":"2023-08-14T05:06:17.150411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load tha train data.\ntrain = pd.read_csv(\"/kaggle/input/bike-sharing-demand/train.csv\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.164697Z","iopub.execute_input":"2023-08-14T05:06:17.165396Z","iopub.status.idle":"2023-08-14T05:06:17.207898Z","shell.execute_reply.started":"2023-08-14T05:06:17.165360Z","shell.execute_reply":"2023-08-14T05:06:17.206445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load tha test data.\ntest = pd.read_csv(\"/kaggle/input/bike-sharing-demand/test.csv\")\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.210128Z","iopub.execute_input":"2023-08-14T05:06:17.210942Z","iopub.status.idle":"2023-08-14T05:06:17.242742Z","shell.execute_reply.started":"2023-08-14T05:06:17.210908Z","shell.execute_reply":"2023-08-14T05:06:17.241679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# preparation the train data","metadata":{}},{"cell_type":"code","source":"# Seeing the shape of the data.\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.244623Z","iopub.execute_input":"2023-08-14T05:06:17.244980Z","iopub.status.idle":"2023-08-14T05:06:17.251224Z","shell.execute_reply.started":"2023-08-14T05:06:17.244949Z","shell.execute_reply":"2023-08-14T05:06:17.250364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seeing if there are dublicated.\ntrain.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.252758Z","iopub.execute_input":"2023-08-14T05:06:17.253957Z","iopub.status.idle":"2023-08-14T05:06:17.277680Z","shell.execute_reply.started":"2023-08-14T05:06:17.253923Z","shell.execute_reply":"2023-08-14T05:06:17.276319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# seeing if there are null values.\ntrain.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.279190Z","iopub.execute_input":"2023-08-14T05:06:17.279998Z","iopub.status.idle":"2023-08-14T05:06:17.294827Z","shell.execute_reply.started":"2023-08-14T05:06:17.279963Z","shell.execute_reply":"2023-08-14T05:06:17.293515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seeing information about data.\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.297604Z","iopub.execute_input":"2023-08-14T05:06:17.297981Z","iopub.status.idle":"2023-08-14T05:06:17.314676Z","shell.execute_reply.started":"2023-08-14T05:06:17.297949Z","shell.execute_reply":"2023-08-14T05:06:17.313856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To unlock a deeper level of analysis and facilitate insightful observations from the dataset, we will Convert the \"datetime\" variable from its current \"object\" type to a structured \"datetime\" format that enriches the dataset. This separation enables more precise temporal analysis, unveiling trends across months, days, and hours.","metadata":{}},{"cell_type":"code","source":"# Convert the 'datetime' column to datetime format\ntrain['datetime'] = pd.to_datetime(train['datetime'])","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.316287Z","iopub.execute_input":"2023-08-14T05:06:17.317035Z","iopub.status.idle":"2023-08-14T05:06:17.327350Z","shell.execute_reply.started":"2023-08-14T05:06:17.317002Z","shell.execute_reply":"2023-08-14T05:06:17.326487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seeing information about data.\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.328721Z","iopub.execute_input":"2023-08-14T05:06:17.329385Z","iopub.status.idle":"2023-08-14T05:06:17.349513Z","shell.execute_reply.started":"2023-08-14T05:06:17.329354Z","shell.execute_reply":"2023-08-14T05:06:17.348427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract the year from the 'datetime' column and create a new 'year' column\ntrain['year'] = train['datetime'].dt.year\n\n# Extract the month as its name from the 'datetime' column and create a new 'month' column\ntrain['month'] = train['datetime'].dt.month_name()\n\n# Extract the day as its name from the 'datetime' column and create a new 'day' column\ntrain['day'] = train['datetime'].dt.day_name()\n\n# Extract the hour from the 'datetime' column and create a new 'hour' column\ntrain['hour'] = train['datetime'].dt.hour\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.372685Z","iopub.execute_input":"2023-08-14T05:06:17.373428Z","iopub.status.idle":"2023-08-14T05:06:17.410458Z","shell.execute_reply.started":"2023-08-14T05:06:17.373378Z","shell.execute_reply":"2023-08-14T05:06:17.409488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In order to further dissect and comprehend the dataset, the datetime variable has been meticulously segmented. This segmentation involves extracting distinct temporal components, namely the year, month, day, and hour, from the datetime column. The result is a more structured representation of time-related data that facilitates seamless analysis and visualization and understanding of bike rental patterns.","metadata":{}},{"cell_type":"code","source":"# Replace the values in the 'season' column with corresponding strings\ntrain['season'].replace({1: 'Spring', 2: 'Summer', 3: 'Fall', 4: 'Winter'}, inplace=True)\n\n# Replace the values in the 'holiday' column with corresponding strings\ntrain['holiday'].replace({1: 'Holiday', 0: 'Not Holiday'}, inplace=True)\n\n# Replace the values in the 'workingday' column with corresponding strings\ntrain['workingday'].replace({1: 'Workingday', 0: 'Not Workingday'}, inplace=True)\n\n# Replace the values in the 'weather' column with corresponding strings\ntrain['weather'].replace({1: 'Clear', 2: 'Mist', 3: 'Rain', 4: 'Snow'}, inplace=True)\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.412145Z","iopub.execute_input":"2023-08-14T05:06:17.412685Z","iopub.status.idle":"2023-08-14T05:06:17.444892Z","shell.execute_reply.started":"2023-08-14T05:06:17.412654Z","shell.execute_reply":"2023-08-14T05:06:17.443560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To improve data clarity and interpretation we replaced numerical values in certain columns with corresponding descriptive strings. This process facilitates a more intuitive understanding of the dataset's categorical attributes and makes it more accessible for analysis and interpretation.","metadata":{}},{"cell_type":"code","source":"# Categorical columns.\ncategorical_features = train[['season', 'holiday', 'workingday', 'weather',  'year', 'month', 'day', 'hour']]\n\nfor i in categorical_features:\n    print(train[i].value_counts())\n    print('-' * 50)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.446873Z","iopub.execute_input":"2023-08-14T05:06:17.447271Z","iopub.status.idle":"2023-08-14T05:06:17.478749Z","shell.execute_reply.started":"2023-08-14T05:06:17.447232Z","shell.execute_reply":"2023-08-14T05:06:17.477503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We've discerned two observations:\n\nFirst, it is the presence of a single value for 'snow' which leads to a potentially negative impact on our analysis. To mitigate this, we chose to combine it with the category 'rain' within the same column.\n\nSecond, we realized that there was a discrepancy between the number of 'holiday' and 'not-workingday', and it was shown in the understanding of the variables that 'workingday' is the day that is neither a weekend nor a holiday. Furthermore, the dataset shows cases where neither 'workingday' nor 'holiday' applies. Thus, this underscores the need for a third variable: the 'weekend'. This variable summarizes scenarios where work or vacation are not active, effectively representing a 'weekend'. This subtle distinction makes clear that our reference to 'holiday' relates exclusively to public holidays, which are distinct from 'weekend' holidays.","metadata":{}},{"cell_type":"code","source":"# Define a mapping dictionary to combine the clusters\ncluster_mapping = {\"Snow\" : \"Rain\"}\n\n# Update the \"grade\" column with the new cluster labels\ntrain['weather'] = train['weather'].replace(cluster_mapping)\n\n# Check the value_counts for the weather after replacing\ntrain['weather'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.480607Z","iopub.execute_input":"2023-08-14T05:06:17.480984Z","iopub.status.idle":"2023-08-14T05:06:17.496978Z","shell.execute_reply.started":"2023-08-14T05:06:17.480952Z","shell.execute_reply":"2023-08-14T05:06:17.495870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filter rows where 'workingday' is equal to 'Workingday'\nworkingDay = train[train['workingday'] == 'Workingday']\n\n# Filter rows where 'holiday' is equal to 'Holiday'\nholiDay = train[train['holiday'] == 'Holiday']\n\n# Filter rows where 'holiday' is not 'Holiday' and 'workingday' is not 'Workingday'\nweekEnd = train[(train['holiday'] == 'Not Holiday') & (train['workingday'] == 'Not Workingday')]","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.698651Z","iopub.execute_input":"2023-08-14T05:06:17.699828Z","iopub.status.idle":"2023-08-14T05:06:17.719717Z","shell.execute_reply.started":"2023-08-14T05:06:17.699772Z","shell.execute_reply":"2023-08-14T05:06:17.718537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Numerical columns.\nnumerical_features = train[['temp', 'atemp', 'humidity', 'windspeed', 'casual', 'registered', 'count']]\n\n# calculate descriptive statistics for numerical values.\nnumerical_features.describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.721372Z","iopub.execute_input":"2023-08-14T05:06:17.722080Z","iopub.status.idle":"2023-08-14T05:06:17.766183Z","shell.execute_reply.started":"2023-08-14T05:06:17.722044Z","shell.execute_reply":"2023-08-14T05:06:17.764878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have identified an issue with wind speed and humidity variables having a minimum value of zero, which is inherently illogical for wind speed or humidity to be zero. As a solution, we will replace these zeros with more reasonable values to ensure data consistency and reliability.","metadata":{}},{"cell_type":"code","source":"# Get the count of the minimum value\ncount_of_min_value = train[train['humidity']==0].shape[0]\n\ncount_of_min_value","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.768388Z","iopub.execute_input":"2023-08-14T05:06:17.768728Z","iopub.status.idle":"2023-08-14T05:06:17.777758Z","shell.execute_reply.started":"2023-08-14T05:06:17.768697Z","shell.execute_reply":"2023-08-14T05:06:17.776489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filter rows with the minimum value\nmin_value_rows = train[train['humidity'] == 0]\n\nmin_value_rows","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.779698Z","iopub.execute_input":"2023-08-14T05:06:17.780242Z","iopub.status.idle":"2023-08-14T05:06:17.816681Z","shell.execute_reply.started":"2023-08-14T05:06:17.780193Z","shell.execute_reply":"2023-08-14T05:06:17.815457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filter rows where the weather is 'Rain'\nrain_weather = train[train['weather'] == 'Rain']\n\n# Calculate the mean humidity for rows with 'Rain' weather\nmean_rain_weather_humidity = rain_weather['humidity'].mean()\n\n# Replace 0 values in the 'humidity' column with the calculated mean for 'Rain' weather\ntrain['humidity'] = train['humidity'].replace(0, mean_rain_weather_humidity)\n\n# Check the minimum value in the 'humidity' column after replacing 0 values\ntrain['humidity'].min()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.819250Z","iopub.execute_input":"2023-08-14T05:06:17.819638Z","iopub.status.idle":"2023-08-14T05:06:17.835182Z","shell.execute_reply.started":"2023-08-14T05:06:17.819604Z","shell.execute_reply":"2023-08-14T05:06:17.833777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We found 22 instances of zero humidity readings, \nIntriguingly, these instances are all recorded on the same day. This suggests a potential recording error for that day's humidity data. \n\nTo address this, we filled these instances with an appropriate value. Given that the day was mostly rainy, we calculated an average humidity value for rainy conditions in the dataset and used it to replace the zeros. This approach ensures data consistency and accuracy despite the recording irregularity.","metadata":{}},{"cell_type":"code","source":"# Get the count of the minimum value\ncount_of_min_value = train[train['windspeed']==0].shape[0]\n\ncount_of_min_value","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.836357Z","iopub.execute_input":"2023-08-14T05:06:17.836705Z","iopub.status.idle":"2023-08-14T05:06:17.847143Z","shell.execute_reply.started":"2023-08-14T05:06:17.836674Z","shell.execute_reply":"2023-08-14T05:06:17.846133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filter rows with the minimum value\nmin_value_rows = train[train['windspeed'] == 0]\n\nmin_value_rows.sample(10)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.849212Z","iopub.execute_input":"2023-08-14T05:06:17.849588Z","iopub.status.idle":"2023-08-14T05:06:17.880627Z","shell.execute_reply.started":"2023-08-14T05:06:17.849552Z","shell.execute_reply":"2023-08-14T05:06:17.879501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace zero 'windspeed with the values above or below\ntrain['windspeed'] = train['windspeed'].replace(0, method='ffill').replace(0, method='bfill')\n\n# Check the minimum value in the 'windspeed' column after replacing 0 values\ntrain['windspeed'].min()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.883559Z","iopub.execute_input":"2023-08-14T05:06:17.884047Z","iopub.status.idle":"2023-08-14T05:06:17.895566Z","shell.execute_reply.started":"2023-08-14T05:06:17.884002Z","shell.execute_reply":"2023-08-14T05:06:17.894152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We've noticed a total of 1313 instances with zero wind speed values scattered throughout the dataset. \n\nTo address this, we're opting to replace these zero values with their adjacent non-zero counterparts. This adjustment aims to approximate more realistic values by maintaining the trend found in the data.","metadata":{}},{"cell_type":"markdown","source":"# Data Visualiation and Analysis","metadata":{}},{"cell_type":"code","source":"# Calculate the correlation matrix for the selected numerical features in the 'data' DataFrame.\ncorrelation_matrix = train[['temp', 'atemp', 'humidity', 'windspeed', 'count']].corr()\n\n# Plot the correlation matrix as a heatmap\nplt.figure(figsize=(18, 6))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', square=True)\nplt.title('Correlation Matrix')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:17.897738Z","iopub.execute_input":"2023-08-14T05:06:17.898359Z","iopub.status.idle":"2023-08-14T05:06:18.317121Z","shell.execute_reply.started":"2023-08-14T05:06:17.898323Z","shell.execute_reply":"2023-08-14T05:06:18.316144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we have seen in the above graph,\n\n1- There is a high correlation between the 'temp' column and the 'atemp' column, so we remove one of them because the two feature act as one feature\n\n2- There is a week positive correlation between the 'temp' column and the target 'count' (0.39), a week negative correlation between the 'humidity' column and the target (-0.32), but there is no correlation between windspeed and the target (0.1).","metadata":{}},{"cell_type":"code","source":"# Calculate counts\ncounts = [workingDay.shape[0], holiDay.shape[0], weekEnd.shape[0]]\nlabels = ['Workingday', 'Holiday', 'Weekend']\n\n# Create a bar chart\nplt.figure(figsize=(18, 6))\nplt.bar(labels, counts)\nplt.xlabel('Variable')\nplt.ylabel('Count')\nplt.title('Counts of Different Variables')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:18.318905Z","iopub.execute_input":"2023-08-14T05:06:18.319438Z","iopub.status.idle":"2023-08-14T05:06:18.622982Z","shell.execute_reply.started":"2023-08-14T05:06:18.319407Z","shell.execute_reply":"2023-08-14T05:06:18.622054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the average rental counts by hour of the day\nhourly_counts = train.groupby('hour')['count'].mean().reset_index()\n\n# Create a line plot to visualize the average rental counts by hour\nplt.figure(figsize=(18, 6))\nsns.lineplot(x='hour', y='count', data=hourly_counts)\nplt.xlabel('Hour of the Day')\nplt.ylabel('Average Rental Counts')\nplt.title('Average Rental Counts by Hour of the Day')\nplt.xticks(ticks=range(24), labels=range(24))\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:18.624585Z","iopub.execute_input":"2023-08-14T05:06:18.625323Z","iopub.status.idle":"2023-08-14T05:06:19.104180Z","shell.execute_reply.started":"2023-08-14T05:06:18.625286Z","shell.execute_reply":"2023-08-14T05:06:19.102987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the mean rental counts per hour based on day of the week\nplt.figure(figsize=(18, 6))\nhour_day_df = train.groupby([\"hour\", \"day\"])[\"count\"].mean().to_frame().reset_index()\nax1 = sns.pointplot(x=hour_day_df[\"hour\"], y=hour_day_df[\"count\"], hue=hour_day_df[\"day\"])\nax1.set_ylabel(\"Mean Count\")","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:19.106889Z","iopub.execute_input":"2023-08-14T05:06:19.107248Z","iopub.status.idle":"2023-08-14T05:06:20.376719Z","shell.execute_reply.started":"2023-08-14T05:06:19.107217Z","shell.execute_reply":"2023-08-14T05:06:20.375367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extracting unique days from the 'day' column of the 'weekEnd' DataFrame\nweekEnd['day'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:20.378303Z","iopub.execute_input":"2023-08-14T05:06:20.378710Z","iopub.status.idle":"2023-08-14T05:06:20.392171Z","shell.execute_reply.started":"2023-08-14T05:06:20.378675Z","shell.execute_reply":"2023-08-14T05:06:20.390849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up the plot\nplt.figure(figsize=(18, 6))\n\n# Create a point plot for 'casual' and 'registered' by 'hour'\nsns.pointplot(data=train, x='hour', y='casual', color='orange', label='casual')\nsns.pointplot(data=train, x='hour', y='registered', color='blue', label='registered')\n\nplt.title('Point Plot of \"casual\" and \"registered\" by Hour')\nplt.xlabel('Hour')\nplt.ylabel('Count')\nplt.legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:20.394614Z","iopub.execute_input":"2023-08-14T05:06:20.395092Z","iopub.status.idle":"2023-08-14T05:06:22.885402Z","shell.execute_reply.started":"2023-08-14T05:06:20.395031Z","shell.execute_reply":"2023-08-14T05:06:22.884280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up the plot\nplt.figure(figsize=(10, 6))\n\n# Create a bar plot to visualize distribution of 'registered' and 'casual' by 'day'\nsns.barplot(data=train, x='day', y='registered', color='blue', label='registered')\nsns.barplot(data=train, x='day', y='casual', color='orange', label='casual')\n\nplt.title('Distribution of \"registered\" and \"casual\" by Day of Week')\nplt.xlabel('Day of Week')\nplt.ylabel('Count')\nplt.legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:22.887348Z","iopub.execute_input":"2023-08-14T05:06:22.887787Z","iopub.status.idle":"2023-08-14T05:06:24.054926Z","shell.execute_reply.started":"2023-08-14T05:06:22.887747Z","shell.execute_reply":"2023-08-14T05:06:24.054089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the total counts for 'casual' and 'registered'\ntotal_casual = train['casual'].sum()\ntotal_registered = train['registered'].sum()\n\n# Calculate the ratios\nratio_casual = total_casual / (total_casual + total_registered)\nratio_registered = total_registered / (total_casual + total_registered)\n\n# Create a bar plot for the ratios of 'casual' and 'registered'\nratios = [ratio_casual, ratio_registered]\nlabels = ['casual', 'registered']\n\nplt.figure(figsize=(8, 6))\nsns.barplot(x=labels, y=ratios)\nplt.title('Ratios of \"casual\" and \"registered\"')\nplt.ylabel('Ratio')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:24.056129Z","iopub.execute_input":"2023-08-14T05:06:24.056926Z","iopub.status.idle":"2023-08-14T05:06:24.337197Z","shell.execute_reply.started":"2023-08-14T05:06:24.056892Z","shell.execute_reply":"2023-08-14T05:06:24.335877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the preceding graphs, a clear pattern emerges: workdays witness the highest bike rental frequency, followed by weekends, and subsequently, official holidays. Notably, the peak hours for bike rentals consistently appear at 7 AM and 5 PM on all days except Saturday and Sunday. During weekends, a shift is apparent, with rental surges occurring from 11 AM to 5 PM.\n\nFurthermore, the data underscores that registered users predominantly utilize bikes during workdays, evident in their peak usage hours at 7 AM and 5 PM. In contrast, casual users, often utilizing bikes for leisure, exhibit pronounced activity during weekends. Consequently, weekends witness a different usage pattern compared to workdays. It's noteworthy that weekend rentals overall tend to be less frequent, accompanied by a higher proportion of casual users.\n\nInterestingly, the dataset features a larger count of registered users compared to casual users. This insight reinforces the prevalence of consistent bike usage patterns among registered users, primarily on workdays, in contrast to the more varied casual usage on weekends.\n\nIn summary, the analysis unveils a notable interplay between user types, work schedules, and rental peak hours, enhancing our understanding of the dynamics behind bike rentals.","metadata":{}},{"cell_type":"code","source":"# Plot the mean rental counts per hour based on season\nplt.figure(figsize=(18, 6))\nhour_season_df = train.groupby([\"hour\", \"season\"])[\"count\"].mean().to_frame().reset_index()\nax2 = sns.pointplot(x=hour_season_df[\"hour\"], y=hour_season_df[\"count\"], hue=hour_season_df[\"season\"])\nax2.set_ylabel(\"Mean Count\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:24.338931Z","iopub.execute_input":"2023-08-14T05:06:24.339669Z","iopub.status.idle":"2023-08-14T05:06:25.274279Z","shell.execute_reply.started":"2023-08-14T05:06:24.339623Z","shell.execute_reply":"2023-08-14T05:06:25.271084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's evident that peak hours for bike rentals remain consistent across seasons, likely due to work-related commuting patterns that persist regardless of the time of year. \n\nInterestingly, despite the consistent peak hour trend, spring stands out with lower bike rental counts. This divergence could be attributed to the prevalence of official holidays during the spring months.","metadata":{}},{"cell_type":"code","source":"# Count the occurrences of each season in the 'season' column of the 'holiDay' DataFrame\nholiDay['season'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:25.279204Z","iopub.execute_input":"2023-08-14T05:06:25.279899Z","iopub.status.idle":"2023-08-14T05:06:25.289027Z","shell.execute_reply.started":"2023-08-14T05:06:25.279861Z","shell.execute_reply":"2023-08-14T05:06:25.287701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code indicates that the prevalence of official holidays is not significantly higher in the spring season, suggesting it might not be the main driver behind the decline in bike rentals during that period. \n\nIn the context of spring, an alternative reason for the reduction could potentially stem from weather conditions. In the heat map analysis, we observed that bike rental counts exhibit a minor negative correlation with humidity and a positive correlation with temperature. This insight reinforces the notion that weather conditions could be contributing to diminished rental activity during the spring season.","metadata":{}},{"cell_type":"code","source":"# Define custom colors for each season\nseason_colors = {\n    'Spring': 'green',\n    'Summer': 'orange',\n    'Fall': 'red',\n    'Winter': 'blue'\n}\n\n# Set up the plot\nplt.figure(figsize=(10, 6))\n\n# Create a kernel density plot of humidity by season with custom colors\nsns.kdeplot(data=train, x='humidity', hue='season', common_norm=False, palette=season_colors.values())\nplt.title('Humidity Density by Seasons')\nplt.xlabel('Humidity')\nplt.ylabel('Density')\nplt.legend(title='Seasons', labels=season_colors.keys())\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:25.290514Z","iopub.execute_input":"2023-08-14T05:06:25.290961Z","iopub.status.idle":"2023-08-14T05:06:25.754640Z","shell.execute_reply.started":"2023-08-14T05:06:25.290926Z","shell.execute_reply":"2023-08-14T05:06:25.753357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define custom colors for each season\nseason_colors = {\n    'Spring': 'green',\n    'Summer': 'orange',\n    'Fall': 'red',\n    'Winter': 'blue'\n}\n\n# Set up the plot\nplt.figure(figsize=(10, 6))\n\n# Create a kernel density plot of temperature by season with custom colors\nsns.kdeplot(data=train, x='temp', hue='season', common_norm=False, palette=season_colors.values())\nplt.title('Temperature Density by Seasons')\nplt.xlabel('Temperature')\nplt.ylabel('Density')\nplt.legend(title='Seasons', labels=season_colors.keys())\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:25.755947Z","iopub.execute_input":"2023-08-14T05:06:25.756656Z","iopub.status.idle":"2023-08-14T05:06:26.219378Z","shell.execute_reply.started":"2023-08-14T05:06:25.756611Z","shell.execute_reply":"2023-08-14T05:06:26.218303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The graphs clearly show that humidity levels during spring are not appreciably high to significantly reduce bike rentals. Furthermore, temperatures are not too low to affect the number of rentals. In fact, during summer, both humidity and temperature are Significantly higher, this did not affect bicycle rentals. Likewise, the remaining seasons show similar levels of humidity and temperature as spring, though only spring has the lowest number of bicycle fares.\n\nThis indicates that weather conditions, while a contributing factor, may not be the only driver of lower rents during the spring season. It is plausible that the distribution of the data could influence this outcome. Spring may have a relatively smaller data set compared to other seasons, which can lead to observed fluctuations in rental numbers.","metadata":{}},{"cell_type":"code","source":"# Calculate the number of days in each season\ndays_in_season = train['season'].value_counts().sort_index()\n\n# Display the number of days in each season\nprint(\"Number of days in each season:\")\nprint(days_in_season)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:26.221082Z","iopub.execute_input":"2023-08-14T05:06:26.221414Z","iopub.status.idle":"2023-08-14T05:06:26.232310Z","shell.execute_reply.started":"2023-08-14T05:06:26.221384Z","shell.execute_reply":"2023-08-14T05:06:26.230964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seeing the distribution of 'season' values in the train dataset\ntrain['season'].value_counts().plot(kind = 'pie', autopct = '%1.1f%%')","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:26.233856Z","iopub.execute_input":"2023-08-14T05:06:26.234175Z","iopub.status.idle":"2023-08-14T05:06:26.410516Z","shell.execute_reply.started":"2023-08-14T05:06:26.234148Z","shell.execute_reply":"2023-08-14T05:06:26.408855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution of data appears remarkably balanced across seasons,  suggesting that it's unlikely the main reason for the lower rental counts in spring.\n\nConsequently, there could be nuanced and less overt reasons within the dataset itself contributing to the reduction in rental counts during the spring season. These factors remain concealed, prompting a need for further exploration to uncover potential underlying causes responsible for this particular trend in the spring season.","metadata":{}},{"cell_type":"markdown","source":"# Data preprocessing","metadata":{}},{"cell_type":"code","source":"# Dropping unnecessary features that are not needed for modeling or have minimal impact\ntrain.drop(['datetime', 'atemp', 'windspeed', 'casual', 'registered'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:26.412886Z","iopub.execute_input":"2023-08-14T05:06:26.413921Z","iopub.status.idle":"2023-08-14T05:06:26.426633Z","shell.execute_reply.started":"2023-08-14T05:06:26.413857Z","shell.execute_reply":"2023-08-14T05:06:26.424959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoding and scalling the data","metadata":{}},{"cell_type":"code","source":"# One hot Endocing .\ntrain = pd.get_dummies(train, columns=['season', 'weather', 'month', 'day'])\n\n# Label Encoding.\nlabel_encoder = LabelEncoder()\n\nfor i in ['holiday', 'workingday', 'year']:\n    train[i] = label_encoder.fit_transform(train[i])","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:26.428770Z","iopub.execute_input":"2023-08-14T05:06:26.430276Z","iopub.status.idle":"2023-08-14T05:06:26.481768Z","shell.execute_reply.started":"2023-08-14T05:06:26.430204Z","shell.execute_reply":"2023-08-14T05:06:26.480627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of columns to scale\ncolumns_to_scale = ['temp', 'humidity', 'hour']\n\n# Create a StandardScaler object\nscaler = StandardScaler()\n\n# Fit the StandardScaler on the selected columns to calculate mean and standard deviation\nscaler.fit(train[columns_to_scale])\n\n# Transform the selected columns using the calculated mean and standard deviation\ntrain[columns_to_scale] = scaler.transform(train[columns_to_scale])\n","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:26.483221Z","iopub.execute_input":"2023-08-14T05:06:26.483816Z","iopub.status.idle":"2023-08-14T05:06:26.496429Z","shell.execute_reply.started":"2023-08-14T05:06:26.483764Z","shell.execute_reply":"2023-08-14T05:06:26.495445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split the data","metadata":{}},{"cell_type":"code","source":"# Split data into x and y.\nX = train.drop(\"count\", axis=1)\ny = train[\"count\"]\n\n# Split train data into train and test.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:26.498078Z","iopub.execute_input":"2023-08-14T05:06:26.498809Z","iopub.status.idle":"2023-08-14T05:06:26.515537Z","shell.execute_reply.started":"2023-08-14T05:06:26.498748Z","shell.execute_reply":"2023-08-14T05:06:26.514160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"# Define the Root Mean Squared Logarithmic Error (RMSLE) scorer\ndef rmsle(y_true, y_pred):\n    return np.sqrt(mean_squared_log_error(y_true, np.clip(y_pred, 0, None)))\n\n# Make the RMSLE scorer\nrmsle_scorer = make_scorer(rmsle)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:26.517141Z","iopub.execute_input":"2023-08-14T05:06:26.517520Z","iopub.status.idle":"2023-08-14T05:06:26.524571Z","shell.execute_reply.started":"2023-08-14T05:06:26.517471Z","shell.execute_reply":"2023-08-14T05:06:26.523185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Root Mean Squared Logarithmic Error (RMSLE) scorer is utilized to assess the model's performance. RMSLE is a metric commonly used in regression tasks to measure the accuracy of predictions. It penalizes underestimation and overestimation of the target variable, making it suitable for this bike rental count prediction task. The lower the RMSLE value, the better the model's predictions align with the actual target values.","metadata":{}},{"cell_type":"code","source":"# Initialize and evaluate different regression models using cross-validation\nmodels = {\n    'Linear Regression': LinearRegression(),\n    'Decision Tree': DecisionTreeRegressor(),\n    'Random Forest': RandomForestRegressor()\n}","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:26.526239Z","iopub.execute_input":"2023-08-14T05:06:26.526624Z","iopub.status.idle":"2023-08-14T05:06:26.539412Z","shell.execute_reply.started":"2023-08-14T05:06:26.526590Z","shell.execute_reply":"2023-08-14T05:06:26.538144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Iterate over each model and Perform cross-validation with RMSLE scorer\nfor model_name, model in models.items():\n    cv_scores = cross_val_score(model, X_train, y_train, scoring=rmsle_scorer, cv=5)\n    \n    print(f\"Model: {model_name}\")\n    print(f\"Average RMSLE: {np.mean(cv_scores)}\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:26.540699Z","iopub.execute_input":"2023-08-14T05:06:26.541089Z","iopub.status.idle":"2023-08-14T05:06:42.835320Z","shell.execute_reply.started":"2023-08-14T05:06:26.541055Z","shell.execute_reply":"2023-08-14T05:06:42.834165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After evaluating multiple regression models, we found that the Random Forest algorithm demonstrated the best performance based on the RMSLE metric. Therefore, we selected the Random Forest model to make predictions on our test data. ","metadata":{}},{"cell_type":"code","source":"# Fit and evaluate the best model on the test set\nthe_model = RandomForestRegressor()  \nthe_model.fit(X_train, y_train)\n\ny_pred = the_model.predict(X_test)\ntest_rmsle = rmsle(y_test, y_pred)\nprint(f\"Test RMSLE for the best model: {test_rmsle}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:42.836908Z","iopub.execute_input":"2023-08-14T05:06:42.837686Z","iopub.status.idle":"2023-08-14T05:06:46.670676Z","shell.execute_reply.started":"2023-08-14T05:06:42.837652Z","shell.execute_reply":"2023-08-14T05:06:46.669516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preperation the test data","metadata":{}},{"cell_type":"code","source":"# Seeing if there are dublicated.\ntest.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:46.672199Z","iopub.execute_input":"2023-08-14T05:06:46.672627Z","iopub.status.idle":"2023-08-14T05:06:46.684179Z","shell.execute_reply.started":"2023-08-14T05:06:46.672594Z","shell.execute_reply":"2023-08-14T05:06:46.682893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# seeing if there are null values.\ntest.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:46.686014Z","iopub.execute_input":"2023-08-14T05:06:46.686915Z","iopub.status.idle":"2023-08-14T05:06:46.699309Z","shell.execute_reply.started":"2023-08-14T05:06:46.686879Z","shell.execute_reply":"2023-08-14T05:06:46.698160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:46.701408Z","iopub.execute_input":"2023-08-14T05:06:46.701853Z","iopub.status.idle":"2023-08-14T05:06:46.721431Z","shell.execute_reply.started":"2023-08-14T05:06:46.701810Z","shell.execute_reply":"2023-08-14T05:06:46.720346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the 'datetime' column to datetime format\ntest['datetime'] = pd.to_datetime(test['datetime'])\n\n# Extract the year from the 'datetime' column and create a new 'year' column\ntest['year'] = test['datetime'].dt.year\n\n# Extract the month as its name from the 'datetime' column and create a new 'month' column\ntest['month'] = test['datetime'].dt.month_name()\n\n# Extract the day as its name from the 'datetime' column and create a new 'day' column\ntest['day'] = test['datetime'].dt.day_name()\n\n# Extract the hour from the 'datetime' column and create a new 'hour' column\ntest['hour'] = test['datetime'].dt.hour","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:46.722969Z","iopub.execute_input":"2023-08-14T05:06:46.723290Z","iopub.status.idle":"2023-08-14T05:06:46.746513Z","shell.execute_reply.started":"2023-08-14T05:06:46.723262Z","shell.execute_reply":"2023-08-14T05:06:46.744744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace the values in the 'season' column with corresponding strings\ntest['season'].replace({1: 'Spring', 2: 'Summer', 3: 'Fall', 4: 'Winter'}, inplace=True)\n\n# Replace the values in the 'holiday' column with corresponding strings\ntest['holiday'].replace({1: 'Holiday', 0: 'Not Holiday'}, inplace=True)\n\n# Replace the values in the 'workingday' column with corresponding strings\ntest['workingday'].replace({1: 'Workingday', 0: 'Not Workingday'}, inplace=True)\n\n# Replace the values in the 'weather' column with corresponding strings\ntest['weather'].replace({1: 'Clear', 2: 'Mist', 3: 'Rain', 4: 'Snow'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:46.748324Z","iopub.execute_input":"2023-08-14T05:06:46.748831Z","iopub.status.idle":"2023-08-14T05:06:46.764154Z","shell.execute_reply.started":"2023-08-14T05:06:46.748773Z","shell.execute_reply":"2023-08-14T05:06:46.762995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a mapping dictionary to combine the clusters\ncluster_mapping = {\"Snow\" : \"Rain\"}\n\n# Update the \"grade\" column with the new cluster labels\ntest['weather'] = test['weather'].replace(cluster_mapping)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:46.770870Z","iopub.execute_input":"2023-08-14T05:06:46.772014Z","iopub.status.idle":"2023-08-14T05:06:46.779951Z","shell.execute_reply.started":"2023-08-14T05:06:46.771969Z","shell.execute_reply":"2023-08-14T05:06:46.778702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Numerical columns.\nnumerical_features = test[['temp', 'atemp', 'humidity', 'windspeed']]\n\n# calculate descriptive statistics for numerical values.\nnumerical_features.describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:46.781628Z","iopub.execute_input":"2023-08-14T05:06:46.782306Z","iopub.status.idle":"2023-08-14T05:06:46.819784Z","shell.execute_reply.started":"2023-08-14T05:06:46.782273Z","shell.execute_reply":"2023-08-14T05:06:46.818603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace zero 'windspeed' with the values above or below\ntest['windspeed'] = test['windspeed'].replace(0, method='ffill').replace(0, method='bfill')","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:46.821823Z","iopub.execute_input":"2023-08-14T05:06:46.822198Z","iopub.status.idle":"2023-08-14T05:06:46.829966Z","shell.execute_reply.started":"2023-08-14T05:06:46.822166Z","shell.execute_reply":"2023-08-14T05:06:46.828582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Store the datetime column in a separate variable.\ndatetime = test['datetime']","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:46.831912Z","iopub.execute_input":"2023-08-14T05:06:46.832475Z","iopub.status.idle":"2023-08-14T05:06:46.840956Z","shell.execute_reply.started":"2023-08-14T05:06:46.832437Z","shell.execute_reply":"2023-08-14T05:06:46.839692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.drop(['datetime', 'atemp', 'windspeed'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:46.842667Z","iopub.execute_input":"2023-08-14T05:06:46.843077Z","iopub.status.idle":"2023-08-14T05:06:46.854718Z","shell.execute_reply.started":"2023-08-14T05:06:46.843046Z","shell.execute_reply":"2023-08-14T05:06:46.853608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One hot Endocing .\ntest = pd.get_dummies(test, columns=['season', 'weather', 'month', 'day'])\n\n# Label Encoding.\nlabel_encoder = LabelEncoder()\n\nfor i in ['holiday', 'workingday', 'year']:\n    test[i] = label_encoder.fit_transform(test[i])","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:46.857247Z","iopub.execute_input":"2023-08-14T05:06:46.857984Z","iopub.status.idle":"2023-08-14T05:06:46.883109Z","shell.execute_reply.started":"2023-08-14T05:06:46.857935Z","shell.execute_reply":"2023-08-14T05:06:46.881923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of columns to scale\ncolumns_to_scale = ['temp', 'humidity', 'hour']\n\n# Create a StandardScaler object\nscaler = StandardScaler()\n\n# Fit the StandardScaler on the selected columns to calculate mean and standard deviation\nscaler.fit(test[columns_to_scale])\n\n# Transform the selected columns using the calculated mean and standard deviation\ntest[columns_to_scale] = scaler.transform(test[columns_to_scale])\n","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:46.884530Z","iopub.execute_input":"2023-08-14T05:06:46.885687Z","iopub.status.idle":"2023-08-14T05:06:46.898963Z","shell.execute_reply.started":"2023-08-14T05:06:46.885646Z","shell.execute_reply":"2023-08-14T05:06:46.897894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction and Submissiom","metadata":{}},{"cell_type":"code","source":"# Generate predictions for the test data using RandomForestClassifier.\ntest_pred = the_model.predict(test)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:06:46.900722Z","iopub.execute_input":"2023-08-14T05:06:46.901954Z","iopub.status.idle":"2023-08-14T05:06:47.052664Z","shell.execute_reply.started":"2023-08-14T05:06:46.901921Z","shell.execute_reply":"2023-08-14T05:06:47.051469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a submission DataFrame with the 'datetime' column and predicted rental counts.\nsubmission = pd.DataFrame({'datetime': datetime, 'count': test_pred})\n","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:12:38.922944Z","iopub.execute_input":"2023-08-14T05:12:38.923414Z","iopub.status.idle":"2023-08-14T05:12:38.930300Z","shell.execute_reply.started":"2023-08-14T05:12:38.923378Z","shell.execute_reply":"2023-08-14T05:12:38.928910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the submission DataFrame as a CSV file without including the index column.\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:12:45.117760Z","iopub.execute_input":"2023-08-14T05:12:45.118393Z","iopub.status.idle":"2023-08-14T05:12:45.170382Z","shell.execute_reply.started":"2023-08-14T05:12:45.118355Z","shell.execute_reply":"2023-08-14T05:12:45.169485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"Our journey of data preparation and analysis has yielded significant insights and successful model utilization. We embarked on a meticulous process of refining the dataset, including datetime format conversion, categorical value replacements, and addressing anomalies in variables like humidity and wind speed. This foundational work set the stage for more accurate analysis and model training.\n\nThrough exploratory data analysis, we unveiled crucial trends and patterns. Notably, we observed that weekdays outshine weekends and holidays in bike rental counts, and specific peak hours consistently attract more rentals.\n\nUpon model evaluation, the Random Forest algorithm demonstrated remarkable prowess by achieving the lowest RMSLE score. \n\nTo sum up, our journey encompassed data refinement, insightful analysis, meticulous model selection, and comprehensive utilization of predictions. This endeavor equips us with valuable information for strategic decision-making.","metadata":{}}]}